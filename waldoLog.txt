5/21/15
The full toolchain is now done; we can generate a de-identified file using a technique
that favors generalization over suppression. The only time we use suppression is if the
set of classes uniquely identifies a student, or if the record when being written out
contains characters that can't be written to a .csv file. We have filters for class
suppression that will pick class/student combinations to suppress at random or based on
favoring suppression of the classes in which the student was the least active. We also have
ways of dynamically determining bins of a minimum size for numeric values and for
geographic locations.

The work needed now is to determine the size of the bins that will lead to a k-anonymous
data set for various values of k. For k = 5 the bins need to be surprisingly large;
currently values of 20,000 lead to more than 55k combinations of values in which 4 or
fewer students reside in the bins.

5/10/15
Time to write the routine that will write out the final, de-identified .csv file.
The fields that we want to write are
    course_id -> course_id
    de-identified student_id -> user_id
    registered -> registered

    viewed -> viewed
    explored -> explored
    certified -> certified
    final-country or region -> final_cc_cname
    Level of education -> LoE
    Year of birth -> YoB
    Gender -> gender
    grade -> grade
    start time -> start_time
    last event -> last_event
    number of events -> nevents
    number of days active -> ndays_act
    number of videos played -> nplay_video
    number of chapters -> nchapters
    number of forum posts -> nforum_posts
    roles -> roles
    incomplete flag -> ???


4/16/15
Simplified the code in edLevelDistribution to only have the list worked on contain the level of education. This
is not quite as simple as it seems, since fetchall() returns a list of tuples, so the resulting list was of
singleton tuples and so still needs to be indexed.

Looked into the data and found that YoB has as possible values both 'NA' and '' for those that hadn't entered
something. Changed buildDB.py to map YoB values of 'NA', those before 1930, and those after 2005 to the value ''.
This will replace the suppression of records with YoB before 1930, which seemed a bit extreme.

Changed the routine in edLevelDistribution that built the dictionary to be more general. It will now build
a dictionary of values/number of records with those values from any list of singleton tuples. You can also
pass in a filter function, which takes a value and can exchange that value for some other, based on whatever
metric you wish. Renamed this function from buildleveldict to builddistdict.

3/19/15
Added code to buildEquivClasses.py to allow the building of the equivalence classes from a .db file as
well as from the .csv.

3/17/15
Back to the code (although some has been generated without adding to the log). Starting by moving all of
the code needed to build the database into buildDB.py, so that it won't clutter up the de_id_functions.py.
Moved splitDate(), idGen2(), and sourceLoad() into the buildDB.py. Also making buildDB.py directly
executable, which should make things easier.

Added a check to buildCourseDict.py to make sure that the courses being added to the dictionary are listed in
a canonical order (I just used dictionary order). It turns out that this makes a difference-- the concatenation
of the classes taken by a student might differ in order only, so putting them in the same order will cut
down on some of the uniqueness.

1/21/15
Starting to build the program that will separately build the database. The thought is to build something that
will take as arguments the .csv file that contains all of the information and the name of the database to output,
and then create something that a version of De-identification.py can use to create a k-anonymous database.

1/29/15
Moved creation of the country/continent table to the buildDB.py function. Have started
to find places where some information was just printed out and moved into places where
it is only printed when a verbose option is picked.

1/8/15
Currently, every time that De-identification.py is run, it builds the whole sqlite
database from a .csv file that contains the information on courses. This database
contains two tables; one which is unmodified and one that is used to anonymize the 
data. 

This functionality can, and should, be split into different programs. One will create
the database, containing a (mostly) unmodified version of the csv file (that itself
contains the course and person data) and another that starts by removing the anonymized 
table, copying the original table, and then working on the anonymization.

In de_id_functions.py:
	Needed to install:
		pycountry
		pp
		pygeoip
	
	changed undeclared and unused variable c to cursor in a number of functions; assumed to be a typo
	
in De-identification.py
	Removed a bad space at line 515
	
